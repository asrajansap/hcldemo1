apiVersion: ai.sap.com/v1alpha1
kind: ServingTemplate
metadata:
  name: st22-shortdump-serving-template
  annotations:
    scenarios.ai.sap.com/name: "Short dump use case"
    scenarios.ai.sap.com/description: "Short dump analysis"
    executables.ai.sap.com/name: "Short-dump-Executable"
    executables.ai.sap.com/description: "Short dump use case analysis"
  labels:
    ai.sap.com/version: "4.0"
    scenarios.ai.sap.com/id: "st22Shortdump"

spec:
  template:
    apiVersion: serving.kserve.io/v1beta1
    kind: InferenceService

    metadata:
      annotations: |
        autoscaling.knative.dev/metric: rps
        autoscaling.knative.dev/target: "100"
        autoscaling.knative.dev/targetBurstCapacity: "70"

    spec: |
      predictor:
        minReplicas: 0
        maxReplicas: 5
        imagePullSecrets:
          - name: rajdoc-registry
        containers:
          - name: kserve-container
            image: docker.io/s0026942030/simple-test:latest
            ports:
              - name: http
                containerPort: 8080
                protocol: TCP
            env:
              - name: LOG_LEVEL
                value: "INFO"
              - name: LLM_PROVIDER
                value: "openai"
              - name: OPENAI_MODEL
                value: "gpt-4o-mini"
              - name: STORAGE_DB
                value: "/app/data/st22.db"
            resources:
              limits:
                cpu: "1"
                memory: "1Gi"
